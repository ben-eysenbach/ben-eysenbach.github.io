<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta charset="UTF-8">
  <link rel="icon" href="images/princeton.png">

  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-88403851-1', 'auto');
    ga('send', 'pageview');

  </script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.3/jquery.min.js"></script>
  <script src="page.js"></script>
  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300" rel="stylesheet" type="text/css">
  <title>Ben Eysenbach</title>
</head>

<body>
  <div id="content">
    <div id="title">
      <h1>Ben Eysenbach</h1>
      <p><b>&#128047; I'm joining Princeton CS starting Fall 2023! &#128047;</b><br>
        Assistant Professor in <a href="https://www.cs.princeton.edu/">Computer Science</a> at <a
          href="https://www.princeton.edu/">Princeton University</a><br>
        eysenbachbe<span style="display:none">spam</span>@gmail.com
        </p>
      <p><a href="#research">Selected Publications</a> / <a href="#talks">Talks</a> / <a
          href="#teaching">Teaching</a> / <a href="https://scholar.google.com/citations?user=DRnOvU8AAAAJ">Google
          Scholar</a> / <a href="https://twitter.com/ben_eysenbach">Twitter</a> /
            <a href="https://drive.google.com/file/d/1iPj70zChmImTM1KGPqS-Vbec-msG7Fxh/view?usp=sharing">PhD Thesis</a></p>
    </div>


    <div class="container" id="intro">
      <img id="profile-img" style="float:right" src="images/me/headshot.jpg" alt="Ben Eysenbach">
      <p>My research aims to develop principled <b>reinforcement learning (RL) algorithms</b> that obtain
        state-of-the-art performance with a higher degree of simplicity, scalability, and robustness than current
        methods. Much of my work uses ideas for probabilistic inference to make progress on a number of problems in RL,
        such as long horizon reasoning [<a href="https://arxiv.org/pdf/1906.05253.pdf">1</a>,<a
          href="https://arxiv.org/abs/2110.12080">2</a>], robustness [<a
          href="https://ben-eysenbach.github.io/rpc/">1</a>,<a href="https://arxiv.org/abs/2103.06257">2</a>],
        representation learning [<a href="https://ben-eysenbach.github.io/contrastive_rl">1</a>,<a
          href="https://ben-eysenbach.github.io/contrastive_rl">2</a>,<a
          href="https://alignedlatentmodels.github.io/">3</a>], and exploration [<a
          href="https://sites.google.com/view/diayn/">1</a>,<a
          href="https://sites.google.com/view/state-marginal-matching">2</a>,<a
          href="https://sites.google.com/corp/view/f-irl/home">3</a>].</p>

      <p>
        <b>Bio:</b> I did my PhD in the Machine Learning Department at Carnegie Mellon University, advised by <a
          href="http://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov</a> and <a
          href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> and supported by the NSF GFRP and the
        Hertz Fellowship. I spent a number of years at <a href="">Google Brain/Research</a> before and during my PhD.
      </p>
      <p><b>Prospective students:</b> I am always looking for fantastic students to join the group. I am especially
        interested in recruiting students who
        <em>(1)</em> have previously worked in chemistry/biology/etc;
        <em>(2)</em> have experience with large-scale computer systems; or
        <em>(3)</em> come from non-traditional/underrepresented backgrounds.
      If you are a current Princeton student, email me. If not, please consider applying to the Princeton CS PhD or MS
      programs. In rare instances I will work with external students.</p>
    </div>

    <div class="container" id="news">
      <h2>News</h2>
      <p>I'll be at ICML to present some fun work with collaborators! Please reach out if you'd like to meet to chat about old or new research.
      <ul class="bullets">
        <li><a href="https://proceedings.mlr.press/v202/eysenbach23a.html">A Connection between One-Step RL and Critic Regularization in RL</a> (<a href="https://www.youtube.com/watch?v=6SwqVXHQjBc">video</a>)</li>
        <li><a href="https://openreview.net/pdf?id=yuLAGjRwk9">Distributional Distance Classifiers for Goal-Conditioned RL</a> (workshop): Led by <a href="https://akella17.github.io/">Ravi Tej Akella</a></li>
        <li><a href="https://openreview.net/pdf?id=yuLAGjRwk9">Offline Goal-Conditioned RL with Latent States as Actions</a> (workshop): Led by <a href="https://seohong.me/">Seohong Park</a></li>
      </ul>
      </p>
      <!-- <table id="news-table" style="padding: 0px 20px"></table> -->
    </div>


    <div class="container" id="research">
      <h2>Selected Publications</h2>
      <p style="margin: 0px 20px">See <a href="https://scholar.google.com/citations?user=DRnOvU8AAAAJ">Google
          Scholar</a> for a complete and up-to-date list of publications.</p>
      <table id="research-table"></table>
      <!-- <p style="text-align: right">*Equal contribution.</p> -->
    </div>

    <div class="container" id="talks">
      <h2>Selected Talks &amp; Podcasts</h2>
      <ul>
        <li><a href="https://generallyintelligent.com/podcast/2023-03-22-podcast-episode-30-ben-eysenbach/">Generally Intelligent Podcast</a> (March 22, 2023)</li>
        <li><a href="https://www.youtube.com/watch?v=8JZYdWbyhCY">The Information Geometry of Unsupervised Reinforcement
            Learning</a> (oral at ICLR 2022)</li>
        <li><a href="https://www.youtube.com/watch?v=7THK9u6UtgE">Replacing Rewards with Examples: Example-Based Policy
            Search via Recursive Classification</a> (oral at NeurIPS 2021)</li>
        <li><a href="https://www.youtube.com/watch?v=T57SxBKVxPQ">C-Learning: Learning to Achieve Goals via Recursive
            Classification</a> (ICLR 2021)</li>
            <li><a href="https://www.talkrl.com/episodes/ben-eysenbach">Talk RL Podcast</a> (March 30, 2020)</li>
        <li><a href="https://www.youtube.com/watch?v=lyIVutL-nXY">Rewriting Experience with Inverse RL: Hindsight
            Inference for Policy Improvement</a> (oral at NeurIPS 2020)</li>
      </ul>
    </div>


    <div class="container" id="teaching">
      <h2>Teaching</h2>
      <!-- <table id="teaching-table"></table> -->
      <ul>
        <li><a href="https://cmudeeprl.github.io/703website/">10-703: Deep Reinforcement Learning</a>. Head TA in Fall
          2019 and Fall 2020.</li>
        <li><a href="http://web.mit.edu/6.008/www/">6.008: Introduction to Inference</a>. TA in Fall 2016.</li>
        <li><a href="http://mit.edu/6.042/">6.042: Math for Computer Science</a>. TA in Spring 2015.</li>
      </ul>
    </div>


    <!--
  <div class="container" id="blog">
    <h2>Assorted Blog Posts</h2>
    <table id="blog-table"></table>
    <hr>
  </div>
  -->

    <div class="container">
      <p id="copyright">Â© 2023 Ben Eysenbach</p>
    </div>


    <!-- spacer to expand content div -->
    <div class="spacer" style="clear: both;"></div>
  </div> <!-- end container div -->

</body>

</html>