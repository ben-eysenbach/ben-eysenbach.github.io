<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Benjamin Eysenbach</title> <meta name="author" content="Benjamin Eysenbach"> <meta name="description" content=""> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.2/css/all.min.css" integrity="" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/princeton.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ben-eysenbach.github.io/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item"> <a class="nav-link" href="https://princeton-rl.github.io/" rel="external nofollow noopener" target="_blank">lab</a> </li> <li class="nav-item "> <a class="nav-link" href="/hiring/">hiring</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks/podcasts</a> </li> <li class="nav-item"> <a class="nav-link" href="https://scholar.google.com/citations?user=DRnOvU8AAAAJ" rel="external nofollow noopener" target="_blank">publications</a> </li> <li class="nav-item"><a class="nav-link" href="https://bsky.app/profile/ben-eysenbach.bsky.social" title="Bluesky" rel="external nofollow noopener" target="_blank"><i class="fab fa-bluesky"></i></a></li> <li class="nav-item"><a class="nav-link" href="https://twitter.com/ben_eysenbach" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a></li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Benjamin</span> Eysenbach </h1> <p class="desc">Assistant Professor of <a href="https://www.cs.princeton.edu/" rel="external nofollow noopener" target="_blank">Computer Science</a> at <a href="https://www.princeton.edu/" rel="external nofollow noopener" target="_blank">Princeton University</a>. <br>Affiliated/Associated Faculty with the <a href="https://cogsci.princeton.edu/" rel="external nofollow noopener" target="_blank">Princeton Program in Cognitive Science</a> and the <a href="https://pli.princeton.edu/" rel="external nofollow noopener" target="_blank">Princeton Language Initiative</a>, and <a href="https://nam.ai.princeton.edu/" rel="external nofollow noopener" target="_blank">Natural and Artificial Minds</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/headshot_small-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/headshot_small-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/headshot_small-1400.webp"></source> <img src="/assets/img/headshot_small.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="headshot_small.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>Room 416</p> <p>35 Olden St</p> <p>Princeton NJ 08544</p> <span style="font-family: monospace">eysenbach@princeton.edu</span> </div> </div> <div class="clearfix"> <p>I design reinforcement learning (RL) algorithms: AI methods that learn how to make intelligent decisions from trial and error. I am especially interested in self-supervised methods, which enable agents to learn intelligent behaviors without labels or human supervision. Our group has developed some of the foremost algorithms and analysis for such self-supervised RL methods. <a href="https://sites.google.com/view/diayn/" rel="external nofollow noopener" target="_blank">Here</a> <a href="https://graliuce.github.io/sgcrl/" rel="external nofollow noopener" target="_blank">are</a> a few example papers; <a href="https://ben-eysenbach.github.io/self-supervised-rl/">here</a> and <a href="https://generative-rl-tutorial.github.io/" rel="external nofollow noopener" target="_blank">here</a> are some tutorials to learn more about our research. My work has been recognized by an NSF CAREER Award, a Hertz Fellowship, an NSF GRFP Fellowship, and the Alfred Rheinstein Faculty Award. I run the <a href="https://princeton-rl.github.io/" rel="external nofollow noopener" target="_blank">Princeton Reinforcement Learning Lab</a>.</p> <p>Before joining Princeton, I did by PhD in machine learning at CMU under <a href="http://www.cs.cmu.edu/~rsalakhu/" rel="external nofollow noopener" target="_blank">Ruslan Salakhutdinov</a> and <a href="https://people.eecs.berkeley.edu/~svlevine/" rel="external nofollow noopener" target="_blank">Sergey Levine</a> and supported by the NSF GFRP and the Hertz Fellowship. I spent a number of years at <a href="https://research.google/" rel="external nofollow noopener" target="_blank">Google Brain/Research</a> before and during my PhD. My undergraduate studies were in math at MIT.</p> <p><strong>Join us!</strong> I am not hiring PhD students in Fall 2025. I am hiring a postdoc. Please read <a href="./hiring">this page</a> before emailing me about joining the lab.</p> </div> <h2>news</h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Dec 1, 2025</th> <td> <img class="emoji" title=":brain:" alt=":brain:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f9e0.png" height="20" width="20"> We’re organizing a NeurIPS 2025 workshop, <a href="https://data-brain-mind.github.io/" rel="external nofollow noopener" target="_blank">Data on the Brain &amp; Mind </a>! Submission deadline for submissions of papers or tutorials is Aug 22. </td> </tr> <tr> <th scope="row">Aug 15, 2025</th> <td> <img class="emoji" title=":apple:" alt=":apple:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f34e.png" height="20" width="20"> Fall 2025 I’m reaching a graduate seminar: <a href="https://ben-eysenbach.github.io/inference-action-f25/">Inference in Action</a>. Join us! </td> </tr> <tr> <th scope="row">Jul 15, 2025</th> <td> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"> Awarded the NSF CAREER award for <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2441665&amp;HistoricalAwards=false" rel="external nofollow noopener" target="_blank">Unsupervised and Autonomous Reinforcement Learning of Skills</a> </td> </tr> <tr> <th scope="row">Jul 14, 2025</th> <td> <img class="emoji" title=":mountain:" alt=":mountain:" src="https://github.githubassets.com/images/icons/emoji/unicode/26f0.png" height="20" width="20"> I gave an ICML tutorial on generative AI and reinforcement learning intrinsic motivation and self-supervised RL, together with <a href="https://amyzhang.github.io/" rel="external nofollow noopener" target="_blank">Amy Zhang</a>. Recording and slides are available on the <a href="https://generative-rl-tutorial.github.io/" rel="external nofollow noopener" target="_blank">tutorial website</a>. </td> </tr> <tr> <th scope="row">Jun 11, 2025</th> <td> <img class="emoji" title=":shamrock:" alt=":shamrock:" src="https://github.githubassets.com/images/icons/emoji/unicode/2618.png" height="20" width="20"> I gave a tutorial on intrinsic motivation and self-supervised RL at <a href="https://rldm.org/" rel="external nofollow noopener" target="_blank">RLDM</a>! Recording and slides are available on the <a href="./self-supervised-rl">tutorial website</a>. </td> </tr> <tr> <th scope="row">Apr 24, 2025</th> <td> <img class="emoji" title=":airplane:" alt=":airplane:" src="https://github.githubassets.com/images/icons/emoji/unicode/2708.png" height="20" width="20"> Princeton RL @ ICLR 2025! Some say hi in Singapore! <ul> <li> <a href="https://graliuce.github.io/sgcrl/" rel="external nofollow noopener" target="_blank">A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals</a>. Led by <a href="https://graliuce.github.io/" rel="external nofollow noopener" target="_blank">Grace Liu</a> and <a href="https://michaeltang.xyz/" rel="external nofollow noopener" target="_blank">Michael Tang</a>.</li> <li> <a href="https://github.com/MichalBortkiewicz/JaxGCRL" rel="external nofollow noopener" target="_blank">Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research</a>. Led by <a href="https://michalbortkiewicz.github.io/" rel="external nofollow noopener" target="_blank">Michał Bortkiewicz</a> and lots of amazing co-authors.</li> <li> <a href="https://horizon-generalization.github.io/" rel="external nofollow noopener" target="_blank">Invariance to Planning in Goal-Conditioned RL</a>. Led by <a href="https://scholar.google.com/citations?user=eXh3y-sAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Cathy Ji</a> and <a href="https://people.eecs.berkeley.edu/~vmyers/" rel="external nofollow noopener" target="_blank">Vivek Myers</a>.</li> <li> <a href="https://arxiv.org/abs/2501.11326" rel="external nofollow noopener" target="_blank">The “Law’’ of the Unconscious Contrastive Learner: Probabilistic Alignment of Unpaired Modalities</a>. Led by <a href="https://yongweiche.github.io/" rel="external nofollow noopener" target="_blank">Yongwei Che</a>.</li> <li> <a href="https://princeton-rl.github.io/contrastive-successor-features/" rel="external nofollow noopener" target="_blank">Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning</a>. Led by <a href="https://chongyi-zheng.github.io/" rel="external nofollow noopener" target="_blank">Chongyi Zheng</a> and <a href="https://jens321.github.io/" rel="external nofollow noopener" target="_blank">Jens Tuyls</a>.</li> <li> <a href="https://seohong.me/projects/ogbench/" rel="external nofollow noopener" target="_blank">OGBench: Benchmarking Offline Goal-Conditioned RL</a>. Led by <a href="https://seohong.me/" rel="external nofollow noopener" target="_blank">Seohong Park</a> and <a href="https://kvfrans.com/" rel="external nofollow noopener" target="_blank">Kevin Frans</a>.</li> </ul> </td> </tr> <tr> <th scope="row">Mar 21, 2025</th> <td> <img class="emoji" title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"> Check out our new preprint, <a href="https://wang-kevin3290.github.io/scaling-crl/" rel="external nofollow noopener" target="_blank">1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities</a>, led by <a href="https://wang-kevin3290.github.io/scaling-crl/" rel="external nofollow noopener" target="_blank">Kevin Wang</a> and <a href="https://ishaanjavali.me/" rel="external nofollow noopener" target="_blank">Ishaan Javali</a> and <a href="https://michalbortkiewicz.github.io/" rel="external nofollow noopener" target="_blank">Michał Bortkiewicz</a>! </td> </tr> <tr> <th scope="row">Feb 1, 2025</th> <td> <img class="emoji" title=":cyclone:" alt=":cyclone:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f300.png" height="20" width="20"> Check out our new preprint, <a href="https://horizon-generalization.github.io/" rel="external nofollow noopener" target="_blank">Horizon Generalization in Reinforcement Learning</a>, led by Cathy Ji and <a href="https://people.eecs.berkeley.edu/~vmyers/" rel="external nofollow noopener" target="_blank">Vivek Myers</a>! </td> </tr> <tr> <th scope="row">Jan 7, 2025</th> <td> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"> Awarded a grant from the <a href="https://ai.princeton.edu/ai-lab" rel="external nofollow noopener" target="_blank">Princeton AI Lab</a> to study ``Do brains perceive, act, and plan using temporal contrast?’’ together with <a href="https://psychology.princeton.edu/people/nathaniel-daw" rel="external nofollow noopener" target="_blank">Nathaniel Daw</a>. </td> </tr> <tr> <th scope="row">Jan 2, 2025</th> <td> <img class="emoji" title=":palm_tree:" alt=":palm_tree:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f334.png" height="20" width="20"> We’re launching a undergraduate research program (REU) together with state and community colleges in NJ. This is a paid program, and no research experience is required. <a href="https://www.cs.princeton.edu/diversity-and-outreach/princeton-research-experience-undergrads-ai-and-machine-learning" rel="external nofollow noopener" target="_blank">Apply</a> by Feb. 1. </td> </tr> </table> </div> </div> <h2>selected publications</h2> <p>The aim is to highlight a small subset of the work done in the group, and to give a sense for the sorts of problems that we're working on. Please see <a href="https://scholar.google.com/citations?user=DRnOvU8AAAAJ" rel="external nofollow noopener" target="_blank">Google Scholar</a> for a complete and up-to-date list of publications.</p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/InFOM.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/InFOM.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/InFOM.gif-1400.webp"></source> <img src="/assets/img/publication_preview/InFOM.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="InFOM.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zheng2025intention" class="col-sm-8"> <div class="title">Intention-Conditioned Flow Occupancy Models</div> <div class="author"> Chongyi Zheng, Seohong Park, Sergey Levine, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>arXiv preprint arXiv:2506.08902</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2506.08902" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/chongyi-zheng/infom" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://chongyi-zheng.github.io/infom/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/epr.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/epr.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/epr.gif-1400.webp"></source> <img src="/assets/img/publication_preview/epr.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="epr.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ji2025identifying" class="col-sm-8"> <div class="title">Identifying nonequilibrium degrees of freedom in high-dimensional stochastic systems</div> <div class="author"> Catherine Ji, Ravin Raj, <em>Benjamin Eysenbach</em>, and Gautam Reddy</div> <div class="periodical"> <em>arXiv preprint arXiv:2508.08247</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2508.08247" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/cj7280/LENS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cube.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cube.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cube.gif-1400.webp"></source> <img src="/assets/img/publication_preview/cube.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cube.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ziarko2025contrastive" class="col-sm-8"> <div class="title">Contrastive Representations for Temporal Reasoning</div> <div class="author"> Alicja Ziarko, Michal Bortkiewicz, Michal Zawalski, <em>Benjamin Eysenbach</em>, and Piotr Milos</div> <div class="periodical"> <em>arXiv preprint arXiv:2508.13113</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2508.13113" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Princeton-RL/CRTR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://princeton-rl.github.io/CRTR/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/misl-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/misl-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/misl-1400.webp"></source> <img src="/assets/img/publication_preview/misl.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="misl.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="misl" class="col-sm-8"> <div class="title">Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning</div> <div class="author"> Chongyi Zheng, Jens Tuyls, Joanne Peng, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2412.08021" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Princeton-RL/contrastive-successor-features" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://princeton-rl.github.io/contrastive-successor-features/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/unconscious-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/unconscious-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/unconscious-1400.webp"></source> <img src="/assets/img/publication_preview/unconscious.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="unconscious.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="unconscious" class="col-sm-8"> <div class="title">The "Law" of the Unconscious Contrastive Learner: Probabilistic Alignment of Unpaired Modalities</div> <div class="author"> Yongwei Che, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2501.11326" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/YongweiChe/UnconsciousContrastiveLearner" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/horizon.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/horizon.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/horizon.gif-1400.webp"></source> <img src="/assets/img/publication_preview/horizon.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="horizon.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="invariance" class="col-sm-8"> <div class="title">Invariance to Planning in Goal-Conditioned RL</div> <div class="author"> Catherine Ji, Vivek Myers, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://horizon-generalization.github.io/static/pdf/horizon_generalization.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/vivekmyers/horizon_generalization" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://horizon-generalization.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/jaxgcrl.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/jaxgcrl.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/jaxgcrl.gif-1400.webp"></source> <img src="/assets/img/publication_preview/jaxgcrl.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="jaxgcrl.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="jaxgcrl" class="col-sm-8"> <div class="title">Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research. Led by Michał Bortkiewicz </div> <div class="author"> Michał Bortkiewicz, Władek Pałucki, Vivek Myers, Tadeusz Dziarmaga, Tomasz Arczewski, Łukasz Kuciński, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2408.11052" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/MichalBortkiewicz/JaxGCRL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/sgcrl.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/sgcrl.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/sgcrl.gif-1400.webp"></source> <img src="/assets/img/publication_preview/sgcrl.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sgcrl.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="singlegoal" class="col-sm-8"> <div class="title">A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals</div> <div class="author"> Grace Liu, Michael Tang, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2408.05804" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/graliuce/sgcrl/tree/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://graliuce.github.io/sgcrl/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/empowerment.svg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/empowerment.svg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/empowerment.svg-1400.webp"></source> <img src="/assets/img/publication_preview/empowerment.svg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="empowerment.svg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="myerslearning" class="col-sm-8"> <div class="title">Learning to Assist Humans without Inferring Rewards</div> <div class="author"> Vivek Myers, Evan Ellis, Sergey Levine, <em>Benjamin Eysenbach</em>, and Anca Dragan</div> <div class="periodical"> <em>In The Thirty-eighth Annual Conference on Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/pdf?id=WCnJmb7cv1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/vivekmyers/empowerment_successor_representations" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://empowering-humans.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/interpolation-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/interpolation-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/interpolation-1400.webp"></source> <img src="/assets/img/publication_preview/interpolation.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="interpolation.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2024inference" class="col-sm-8"> <div class="title">Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference</div> <div class="author"> <em>Benjamin Eysenbach</em>, Vivek Myers, Russ Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In The Thirty-eighth Annual Conference on Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/pdf?id=PoCs4jq7cV" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/vivekmyers/contrastive_planning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cmd-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cmd-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cmd-1400.webp"></source> <img src="/assets/img/publication_preview/cmd.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cmd.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="myers2024learning" class="col-sm-8"> <div class="title">Learning Temporal Distances: Contrastive Successor Features Can Provide a Metric Structure for Decision-Making</div> <div class="author"> Vivek Myers, Chongyi Zheng, Anca Dragan, Sergey Levine, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In Forty-first International Conference on Machine Learning</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2406.17098" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/vivekmyers/contrastive_metrics" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/raj_augmentation-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/raj_augmentation-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/raj_augmentation-1400.webp"></source> <img src="/assets/img/publication_preview/raj_augmentation.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="raj_augmentation.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ghugare2024closing" class="col-sm-8"> <div class="title">Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View</div> <div class="author"> Raj Ghugare, Geist Matthieu, Glen Berseth, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2401.11237" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/RajGhugare19/stitching-is-combinatorial-generalisation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/td_cpc.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/td_cpc.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/td_cpc.gif-1400.webp"></source> <img src="/assets/img/publication_preview/td_cpc.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="td_cpc.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zheng2023contrastive" class="col-sm-8"> <div class="title">Contrastive Difference Predictive Coding</div> <div class="author"> Chongyi Zheng, Ruslan Salakhutdinov, and <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2310.20141" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/chongyi-zheng/td_infonce" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://chongyi-zheng.github.io/td_infonce/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/stabilizing.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/stabilizing.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/stabilizing.gif-1400.webp"></source> <img src="/assets/img/publication_preview/stabilizing.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="stabilizing.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="anonymous2024stabilizing" class="col-sm-8"> <div class="title">Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data</div> <div class="author"> Chongyi Zheng, <em>Benjamin Eysenbach</em>, Homer Walke, Patrick Yin, Kuan Fang, Ruslan Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2306.03346.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/chongyi-zheng/stable_contrastive_rl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://chongyi-zheng.github.io/stable_contrastive_rl/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cvl-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cvl-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cvl-1400.webp"></source> <img src="/assets/img/publication_preview/cvl.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cvl.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mazoure2023contrastive" class="col-sm-8"> <div class="title">Contrastive value learning: Implicit Models for Simple Offline RL</div> <div class="author"> Bogdan Mazoure, <em>Benjamin Eysenbach</em>, Ofir Nachum, and Jonathan Tompson</div> <div class="periodical"> <em>In Conference on Robot Learning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://openreview.net/pdf?id=oqOfLP6bJy" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://openreview.net/attachment?id=oqOfLP6bJy&amp;name=supplementary_material" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://openreview.net/attachment?id=oqOfLP6bJy&amp;name=poster_spotlight_video" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/alm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/alm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/alm-1400.webp"></source> <img src="/assets/img/publication_preview/alm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="alm.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ghugare2023simplifying" class="col-sm-8"> <div class="title">Simplifying Model-based RL: Learning Representations, Latent-space Models, and Policies with One Objective</div> <div class="author"> Raj Ghugare, Homanga Bharadhwaj, <em>Benjamin Eysenbach</em>, Sergey Levine, and Russ Salakhutdinov</div> <div class="periodical"> <em>In International Conference on Learning Representations </em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2209.08466" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/RajGhugare19/alm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://alignedlatentmodels.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ac_connection-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ac_connection-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ac_connection-1400.webp"></source> <img src="/assets/img/publication_preview/ac_connection.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ac_connection.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pmlr-v202-eysenbach23a" class="col-sm-8"> <div class="title">A Connection between One-Step RL and Critic Regularization in Reinforcement Learning</div> <div class="author"> <em>Benjamin Eysenbach</em>, Matthieu Geist, Sergey Levine, and Ruslan Salakhutdinov</div> <div class="periodical"> <em>In International Conference on Machine Learning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://proceedings.mlr.press/v202/eysenbach23a/eysenbach23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/laeo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/laeo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/laeo-1400.webp"></source> <img src="/assets/img/publication_preview/laeo.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="laeo.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pmlr-v211-hatch23a" class="col-sm-8"> <div class="title">Contrastive Example-Based Control</div> <div class="author"> Kyle Beltran Hatch, <em>Benjamin Eysenbach</em>, Rafael Rafailov, Tianhe Yu, Ruslan Salakhutdinov, Sergey Levine, and Chelsea Finn</div> <div class="periodical"> <em>In Learning for Dynamics and Control Conference</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://proceedings.mlr.press/v211/hatch23a/hatch23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/thesis-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/thesis-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/thesis-1400.webp"></source> <img src="/assets/img/publication_preview/thesis.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="thesis.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2023thesis" class="col-sm-8"> <div class="title">Probabilistic Reinforcement Learning: Using Data to Define Desired Outcomes, and Inferring How to Get There</div> <div class="author"> <em>Benjamin Eysenbach</em> </div> <div class="periodical"> <em>PhD Thesis, Carnegie Mellon University</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://drive.google.com/file/d/1iPj70zChmImTM1KGPqS-Vbec-msG7Fxh/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/mnm_lower_bound.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/mnm_lower_bound.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/mnm_lower_bound.gif-1400.webp"></source> <img src="/assets/img/publication_preview/mnm_lower_bound.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="mnm_lower_bound.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2021mismatched" class="col-sm-8"> <div class="title">Mismatched No More: Joint Model-Policy Optimization for Model-Based RL</div> <div class="author"> <em>Benjamin Eysenbach</em>, Alexander Khazatsky, Sergey Levine, and Ruslan Salakhutdinov</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2110.02758" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ben-eysenbach/mnm/blob/main/experiments.ipynb" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://youtu.be/AbBTq0LON3Q" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/contrastive.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/contrastive.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/contrastive.gif-1400.webp"></source> <img src="/assets/img/publication_preview/contrastive.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="contrastive.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2022contrastive" class="col-sm-8"> <div class="title">Contrastive Learning as Goal-Conditioned Reinforcement Learning</div> <div class="author"> <em>Benjamin Eysenbach</em>, Tianjun Zhang, Ruslan Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2206.07568.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/google-research/google-research/tree/master/contrastive_rl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://youtu.be/5_eGcprfw60" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://ben-eysenbach.github.io/contrastive_rl" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ocbc.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ocbc.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ocbc.gif-1400.webp"></source> <img src="/assets/img/publication_preview/ocbc.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ocbc.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="NEURIPS2022_284afdc2" class="col-sm-8"> <div class="title">Imitating Past Successes can be Very Suboptimal</div> <div class="author"> <em>Benjamin Eysenbach</em>, Soumith Udatha, Russ R Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/284afdc2309f9667d2d4fb9290235b0c-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ben-eysenbach/normalized-ocbc/blob/main/experiments.ipynb" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://youtu.be/bXnnU68HYQA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/info_geometry.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/info_geometry.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/info_geometry.gif-1400.webp"></source> <img src="/assets/img/publication_preview/info_geometry.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="info_geometry.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2022the" class="col-sm-8"> <div class="title">The Information Geometry of Unsupervised Reinforcement Learning</div> <div class="author"> <em>Benjamin Eysenbach</em>, Ruslan Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2110.02719" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ben-eysenbach/info_geometry/blob/main/experiments.ipynb" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.youtube.com/watch?v=8JZYdWbyhCY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/maxent_robust.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/maxent_robust.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/maxent_robust.gif-1400.webp"></source> <img src="/assets/img/publication_preview/maxent_robust.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="maxent_robust.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2022maximum" class="col-sm-8"> <div class="title">Maximum Entropy RL (Provably) Solves Some Robust RL Problems</div> <div class="author"> <em>Benjamin Eysenbach</em>, and Sergey Levine</div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2103.06257" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://bair.berkeley.edu/blog/2021/03/10/maxent-robust-rl/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/rce.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/rce.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/rce.gif-1400.webp"></source> <img src="/assets/img/publication_preview/rce.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="rce.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2021replacing" class="col-sm-8"> <div class="title">Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification</div> <div class="author"> <em>Benjamin Eysenbach</em>, Sergey Levine, and Ruslan Salakhutdinov</div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2103.12656.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://ai.googleblog.com/2021/03/recursive-classification-replacing.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/google-research/google-research/tree/master/rce" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://ben-eysenbach.github.io/rce/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/c_learning_sawyer.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/c_learning_sawyer.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/c_learning_sawyer.gif-1400.webp"></source> <img src="/assets/img/publication_preview/c_learning_sawyer.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="c_learning_sawyer.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2020c" class="col-sm-8"> <div class="title">C-Learning: Learning to Achieve Goals via Recursive Classification</div> <div class="author"> <em>Benjamin Eysenbach</em>, Ruslan Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/2011.08909.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/google-research/google-research/tree/master/c_learning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://ben-eysenbach.github.io/c_learning/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/rpc_teaser.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/rpc_teaser.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/rpc_teaser.gif-1400.webp"></source> <img src="/assets/img/publication_preview/rpc_teaser.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="rpc_teaser.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2021robust" class="col-sm-8"> <div class="title">Robust Predictable Control</div> <div class="author"> <em>Benjamin Eysenbach</em>, Ruslan Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2109.03214" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/google-research/google-research/tree/master/rpc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.youtube.com/watch?v=6efUoVvhmpQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://ben-eysenbach.github.io/rpc" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/sorb-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/sorb-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/sorb-1400.webp"></source> <img src="/assets/img/publication_preview/sorb.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sorb.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2019search" class="col-sm-8"> <div class="title">Search on the replay buffer: Bridging planning and reinforcement learning</div> <div class="author"> <em>Benjamin Eysenbach</em>, Ruslan Salakhutdinov, and Sergey Levine</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1906.05253.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://blog.ml.cmu.edu/2020/02/13/rl-for-planning-and-planning-for-rl/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="http://bit.ly/rl_search" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/diayn.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/diayn.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/diayn.gif-1400.webp"></source> <img src="/assets/img/publication_preview/diayn.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="diayn.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="eysenbach2018diversity" class="col-sm-8"> <div class="title">Diversity is All You Need: Learning Skills without a Reward Function</div> <div class="author"> <em>Benjamin Eysenbach</em>, Abhishek Gupta, Julian Ibarz, and Sergey Levine</div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/pdf/1802.06070" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/haarnoja/sac/blob/master/DIAYN.md" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://sites.google.com/view/diayn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Benjamin Eysenbach. <span style="float:right;"> Last updated: September 16, 2025. </span> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>