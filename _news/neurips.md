---
layout: post
date: 2025-12-01 12:00:00-0400
inline: true
related_posts: false
---

:palm\_tree: Princeton RL @ NeurIPS 2025! I'm excited to share progress we've made in RL algorithms (and the many problems still unsolved):
* :rocket: [1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities](https://wang-kevin3290.github.io/scaling-crl/), led by [Kevin Wang](https://wang-kevin3290.github.io/scaling-crl/) and [Ishaan Javali](https://ishaanjavali.me/) and [Michał Bortkiewicz](https://michalbortkiewicz.github.io/). (oral)
* :ocean: [Normalizing Flows are Capable Models for RL](https://rajghugare19.github.io/nf4rl/). Led by [Raj Ghugare](https://github.com/RajGhugare19).
* :abacus: [Contrastive Representations for Temporal Reasoning](https://princeton-rl.github.io/CRTR/) Led by [Alicja Ziarko](https://x.com/ZiarkoAlicja), with [Michal Bortkiewicz](https://michalbortkiewicz.github.io/), [Michal Zawalski](https://michalzawalski.github.io/), and [Piotr Milos](https://www.mimuw.edu.pl/~pmilos/).
* :clamp: [Horizon Reduction Makes Offline RL Scalable](https://github.com/seohongpark/horizon-reduction). Let by [Seohong Park](https://seohong.me/), with [Kevin Frans](https://kvfrans.com/), Deepinder Mann, [Aviral Kumar](https://aviralkumar2907.github.io/), [Sergey Levine](https://people.eecs.berkeley.edu/~svlevine/). (spotlight)

We're also presenting preliminary work at several of the workshops:
* [Low-Rank Successor Representations Capture Human-Like Generalization](). Led by Eva Yi Xie, with Nathaniel D. Daw. <span style="color:#aaa;">(Unifying Representations in Neural Models)</span>
* [Structured Response Diversity with Mutual Information](). Led by Devan Shah, Owen Yang, and Daniel Yang, with Chongyi Zheng. <span style="color:#aaa;">(Scaling Environments for Agents)</span>
* [Demystifying emergent exploration in goal-conditioned RL](). Led by Mahsa Bastankhah and Grace Liu, with Dilip Arumugam and Thomas L. Griffiths. <span style="color:#aaa;">(Aligning Reinforcement Learning Experimentalists and Theorists;  Interpreting Cognition in Deep Learning Models)</span>
* [Training LLM Agents to Empower Humans](). Evan Ellis, Vivek Myers, Jens Tuyls, Sergey Levine, Anca Dragan. <span style="color:#aaa;">(Deep Learning for Code)</span>
* [Unsupervised Contrastive Goal Reaching](). Led by Ahmed Turkman, with Raj Ghugare. <span style="color:#aaa;">(Aligning Reinforcement Learning Experimentalists and Theorists)</span>
* [Combinatorial Representations for Temporal Reasoning](). Led by Alicja Ziarko, with Michał Bortkiewicz, Michał Zawalski, Piotr Miłoś. <span style="color:#aaa;">(Differentiable Learning of Combinatorial Algorithms; Unifying Representations in Neural Models; WiML)</span>
* [Horizon Reduction Makes Offline RL Scalable](). Led by Seohong Park, with Kevin Frans, Deepinder Mann, Aviral Kumar, Sergey Levine. <span style="color:#aaa;">(Aligning Reinforcement Learning Experimentalists and Theorists)</span>

:brain: Finally, I'm organizing a NeurIPS 2025 workshop, [Data on the Brain & Mind](https://data-brain-mind.github.io/), together with [Eva Yi Xie](https://minzsiure.github.io/), [Catherine Ji](https://phy.princeton.edu/people/cathy-ji), [Vivek Myers](https://phy.princeton.edu/people/cathy-ji), [Archer Wang](https://github.com/archerw105/), [Mahsa Bastankhah](https://sites.google.com/view/mahsabastankhah/home), [Jenelle Feather](https://www.jenellefeather.com/), [Erin Grant](https://eringrant.github.io/), and [Richard Gao](https://www.rdgao.com/). On December 7th.

